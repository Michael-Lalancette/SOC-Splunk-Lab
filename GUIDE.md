## üìë Table des mati√®res

- [Phase 1 ‚Äî R√©seaux virtuels](#phase-1---r√©seaux-virtuels)
  - [VMnet1 (Host-Only)](#vmnet1-host-only)
  - [VMnet8 (NAT/DHCP)](#vmnet8-natdhcp)

- [Phase 2 ‚Äî Configuration des VMs](#phase-2---configuration-des-vms)
  - [SOC-Splunk-Server](#Ô∏è-soc-splunk-server)
  - [SOC-W11](#Ô∏è-soc-w11)
  - [SOC-ATK](#Ô∏è-soc-atk)
  - [SOC-Workstation](#Ô∏è-soc-workstation)

- [Phase 3 ‚Äî Installation de Splunk Enterprise](#phase-3---installation-de-splunk-enterprise)
- [Phase 4 ‚Äî D√©ploiement du Universal Forwarder (SOC-W11)](#phase-4---d√©ploiement-du-universal-forwarder-soc-w11)
- [Phase 5 ‚Äî Configuration du Honeypot](#phase-5---configuration-du-honeypot)
- [Phase 6 ‚Äî Configuration des Alertes](#phase-6---configuration-des-alertes)
- [Phase 7 ‚Äî Reconnaissance simul√©e](#phase-7---reconnaissance-simulee)
- [Phase 8 ‚Äî Flow SOC](#phase-8---flow-soc)




---





## Phase 1 - R√©seaux virtuels

### üéØ Objectif
Mettre en place deux r√©seaux virtuels sous VMware pour le laboratoire :  
  - Un r√©seau isol√© (Host-Only) pour la communication interne entre les VMs du lab, sans passerelle vers l‚Äôext√©rieur.  
  - Un r√©seau externe (NAT) pour fournir temporairement un acc√®s internet aux VMs (mises √† jour et t√©l√©chargements d‚Äôoutils).  


### VMnet1 (Host-Only)
  - Cr√©er/configurer un r√©seau Host-Only d√©di√©.  
  - D√©sactiver le DHCP.
  - Plage IP : `10.7.0.0/24` (adresses attribu√©es manuellement).
  > **R√©sultat‚ÄØ‚úÖ :** Les VMs connect√©es √† VMnet1 communiquent entre elles uniquement, sans acc√®s √† internet ni au r√©seau physique de l‚Äôh√¥te.  
  ![VMnet1](./images/vmnet1.png)


### VMnet8 (NAT/DHCP)
  - Activ√© par d√©faut dans VMware.
  - Laisser le DHCP activ√© (distribution auto d‚Äôadresses).
  - Plage IP : `172.16.0.0/24` (adresses attribu√©es dynamiquement aux VMs).
  - Ce r√©seau utilise le NAT (Network Address Translation) pour fournir un acc√®s internet aux VMs.  
  > **R√©sultat ‚úÖ‚ÄØ:** Les VMs connect√©es √† VMnet8 peuvent acc√©der √† internet pour t√©l√©chargements et mises √† jour. 
  ![VMnet8](./images/vmnet8.png)





---





## Phase 2 - Configuration des VMs

### üéØ Objectif
D√©ployer et pr√©parer les machines virtuelles du laboratoire : d√©finir les ressources, configurer les interfaces r√©seau, installer les paquets de base, et effectuer des v√©rifications simples avant la phase d‚Äôapplication.


### üñ•Ô∏è SOC-Splunk-Server
  **Specs** : 
  - OS : üëâ [Ubuntu Server 24.04.03 LTS](https://ubuntu.com/download/server) 
  - vCPU : 4
  - RAM : 12GB
  - Disque : 100GB
  - NIC1 : Host-only (`10.7.0.10/24`)
  - NIC2 : NAT/DHCP (`172.16.0.x/24`) - temporaire


  **Configuration r√©seau** :
  - Choisir installation minimale pour garder contr√¥le sur les paquets install√©s.
  
  - Configuration de **eth0** ‚Äì r√©seau interne (Host‚ÄëOnly, adresse statique)
    - Adresse IPv4 : `10.7.0.10`
    - DNS : `8.8.8.8`
        
    > üí° Pourquoi pas de Gateway? Le r√©seau host-only est non rout√© : indiquer une gateway pousserait tout le trafic non-local vers un chemin inexistant et provoquerait des pertes de connectivit√©.
    ![splunk-ipv4-1](./images/splunk-ipv4-1.png)

  - Configuration de **eth1** ‚Äì r√©seau externe (NAT, adresse dynamique via DHCP) :
    - Mode : DHCP automatique.
    - L‚Äôinterface re√ßoit une IP dynamique (ex : `172.16.0.129`).
        
    > üí° Fournit acc√®s Internet (mises √† jour + t√©l√©chargement de Splunk).  
    ![splunk-dhcp-1](./images/splunk-dhcp-1.png)

  - Apr√®s le reboot de la machine, installer paquets essentiels et activer SSH :
      ```bash
      # Installer paquets
      sudo apt update
      sudo apt install -y openssh-server iputils-ping curl net-tools

      # Activer/d√©marrer SSH au boot
      sudo systemctl enable --now ssh

      # V√©rifier SSH
      systemctl status ssh
      ```


  **‚úÖ V√©rifications** :  
  - `ip -br a` ‚Üí confirme la pr√©sence des deux interfaces (`10.7.0.10` et `172.16.0.129`).
  - `ping 8.8.8.8 -c 3` ‚Üí v√©rifie la connectivit√© Internet.  
   ![splunk-verif](./images/splunk-verif.png)


> ‚ö†Ô∏è Prendre un snapshot de la VM juste avant d‚Äôinstaller Splunk, afin de pouvoir revenir rapidement en cas de probl√®me.



---



### üñ•Ô∏è SOC-W11
  **Specs** : 
  - OS : üëâ [Microsoft Windows 11 ISO](https://www.microsoft.com/en-us/software-download/windows11?msockid=3093134cf4a46e83086606b8f5856f87)
  - vCPU : 2
  - RAM : 4GB
  - Disque : 60GB
  - NIC1 : Host-only (`10.7.0.20/24`)
  - NIC2 : NAT/DHCP (`172.16.0.x/24`) - temporaire

  **Configuration r√©seau** :  
  - Configuration de **eth0** ‚Äì r√©seau interne (Host‚ÄëOnly, adresse statique)  
      1. `Win + R` ‚Üí taper `ncpa.cpl` ‚Üí OK (ouvre directement Connexions r√©seau)
      2. Ethernet ‚Üí Propri√©t√©s ‚Üí Internet Protocol Version 4 (TCP/IPv4)  

    ![w11-eth0](./images/w11-eth0.png)

  - Configuration de **eth1** ‚Äì r√©seau externe (NAT, adresse dynamique via DHCP) :
    - Mode : DHCP automatique.
    - L‚Äôinterface re√ßoit une IP dynamique (ex : `172.16.0.130`).

    ![w11-eth1](./images/w11-eth1.png)


  **‚úÖ V√©rifications** :  
  - `ipconfig` ‚Üí confirme la pr√©sence des deux interfaces (`10.7.0.20` et `172.16.0.130`).
  - `ping 8.8.8.8 -n 3` ‚Üí v√©rifie la connectivit√© Internet.
  - `ping 10.7.0.10 -n 3` ‚Üí v√©rifie la connectivit√© avec le serveur Splunk.  
   ![w11-verif-1](./images/w11-verif-1.png)  
   ![w11-verif-2](./images/w11-verif-2.png)


> ‚ö†Ô∏è Prendre un snapshot "clean" de la VM en cas d'incident.




---




### üñ•Ô∏è SOC-ATK
  **Specs** : 
  - OS : üëâ [Kali Linux ](https://www.kali.org/)
  - vCPU : 2
  - RAM : 4GB
  - Disque : 40GB
  - NIC1 : Host-only (`10.7.0.30/24`)
  - NIC2 : NAT/DHCP (`172.16.0.x/24`) - temporaire

  **Configuration r√©seau (netplan)** :  
  - Interface‚ÄØ**eth0** ‚Äì r√©seau interne (Host‚ÄëOnly, adresse statique)
    ```bash
    sudo nmcli con add type ethernet ifname eth0 con-name eth0-static ipv4.addresses 10.7.0.30/24 ipv4.dns "8.8.8.8 1.1.1.1" ipv4.method manual
    sudo nmcli con up eth0-static
    ```

  - Interface‚ÄØ**eth1** ‚Äì r√©seau externe (NAT, adresse dynamique via DHCP)
    ```bash
    sudo nmcli con add type ethernet ifname eth1 con-name eth1-dhcp ipv4.method auto
    sudo nmcli con up eth1-dhcp
    ```
    ![kali-cli-eth](./images/kali-cli-eth.png)   

    > üí° Remarque‚ÄØ: selon la version de Kali, les interfaces peuvent √™tre renomm√©es (ex : ens33, ens34, etc.).    
    >  Identifiez les noms exacts avec la commande `ip -br a` et adaptez les param√®tres `ifname` en cons√©quence.  

  **‚úÖ V√©rifications** :  
  - `ip -br a` ‚Üí confirme la pr√©sence des deux interfaces (`10.7.0.30` et `172.16.0.131`).
  - `ping 8.8.8.8 -c 3` ‚Üí v√©rifie la connectivit√© Internet.
  - `ping 10.7.0.[10-20] -c 3` ‚Üí v√©rifie la connectivit√© avec les diff√©rentes VMs.
    ![kali-cli-verif-1](./images/kali-cli-verif-1.png)    
    ![kali-cli-verif-2](./images/kali-cli-verif-2.png)     

  > ‚ö†Ô∏è Pour autoriser le ping vers la machine Windows, il faut activer la r√®gle **ICMPv4-In** dans le pare-feu de la machine Windows.    
    ![win11-firewall-icmpv4](./images/win11-firewall-icmpv4.png)  
  > Une fois la r√®gle activ√©e, la commande `ping 10.7.0.20 -c 3` confirme la connectivit√©.  


> ‚ö†Ô∏è Prendre un snapshot "clean" de la VM en cas d'incident.




  ---




### üñ•Ô∏è SOC-Workstation
  **Specs** : 
  - OS : üëâ [Ubuntu Desktop 24.04.3 LTS](https://ubuntu.com/download/desktop)
  - vCPU : 4
  - RAM : 8GB
  - Disque : 40GB
  - NIC1 : Host-only (`10.7.0.40/24`)
  - NIC2 : NAT/DHCP (`172.16.0.x/24`) - temporaire

  **Configuration r√©seau** :
  - Configuration de **eth0/ens33** ‚Äì r√©seau interne (Host‚ÄëOnly, adresse statique)
    - Adresse IPv4 : `10.7.0.40`
    - Netmask : `255.255.255.0`
    - DNS : `8.8.8.8, 1.1.1.1`
    
    ![soc-eth0](./images/soc-eth0.png)


  - Configuration de **eth1/ens34** ‚Äì r√©seau externe (NAT, adresse dynamique via DHCP) :
    - Dans IPv4 : IPv4 Method = Automatic (DHCP).
    - L‚Äôinterface re√ßoit une IP dynamique (ex : `172.16.0.132`).



  **‚úÖ V√©rifications** :  
  - `ip -br a` ‚Üí confirme la pr√©sence des deux interfaces  (`10.7.0.40` et `172.16.0.132`).
  - `ping 8.8.8.8 -c 3` ‚Üí v√©rifie la connectivit√© Internet.
  - `ping 10.7.0.[10-30] -c 3` ‚Üí v√©rifie la connectivit√© avec les diff√©rentes VMs.

    ![soc-verif-1](./images/soc-verif-1.png)    
    ![soc-verif-2](./images/soc-verif-2.png)  

> ‚ö†Ô∏è Prendre un snapshot "clean" de la VM en cas d'incident.



---



## üìä Tableau R√©capitulatif
| VM                | OS                   | eth0 (Host-only) | eth1 (NAT/DHCP) | R√¥le            |
| ----------------- | -------------------- | ---------------- | --------------- | --------------- |
| SOC-Splunk-Server | Ubuntu Server 24.04  | 10.7.0.10/24     | DHCP            | Collecte & SIEM |
| SOC-W11           | Windows 11           | 10.7.0.20/24     | DHCP            | Victime         |
| SOC-ATK           | Kali Linux           | 10.7.0.30/24     | DHCP            | Attaquant       |
| SOC-Workstation   | Ubuntu Desktop 24.04 | 10.7.0.40/24     | DHCP            | Analyste        |



---




## Phase 3 - Installation de Splunk Enterprise

### üéØ Objectif  
Installer Splunk Enterprise sur la VM `SOC-Splunk-Server`, activer le service, configurer l‚Äôautostart et valider l‚Äôacc√®s au tableau de bord depuis la station analyste.



### 1. T√©l√©chargement de Splunk Enterprise  
  - Naviguer sur la page [Splunk Enterprise](https://www.splunk.com/en_us/download/splunk-enterprise.html).  
  - Cr√©er un compte Splunk et choisir l‚Äôinstallateur Linux `.deb`.  
  - Copier le lien `wget` fourni par Splunk.  
> üí° Cette URL sera utilis√©e plus tard avec `wget`depuis le serveur Ubuntu.  
    ![splunk-download](./images/splunk-download.png) 



### 2. Connexion SSH 
  - Depuis la VM SOC-Workstation (Ubuntu Desktop), se connecter sur le serveur Ubuntu via SSH :  
    ```bash
    ssh splunk-admin@10.7.0.10
    ```
    ![ssh](./images/ssh.png)  



### 3. R√©cup√©ration et installation
  - R√©cup√©rer le fichier `.deb` avec `wget` :  
    ```bash
    wget -O splunk.deb "<URL_copi√©e_avec_wget>"
    ```  
    ![splunk-download-2](./images/splunk-download-2.png)
      
    > N.B. : `-O` nomme sp√©cifiquement le fichier `splunk.deb` (beaucoup mieux que le long string par d√©faut).

  - Installer le paquet Splunk :  
    ```bash
    sudo dpkg -i splunk.deb
    ```  
  - Lancer Splunk et accepter la license :
    ```bash
    sudo /opt/splunk/bin/splunk start --accept-license
    ```  
  - Cr√©er le compte admin (`splunk-admin`) et lui associer un mot de passe appropri√©.
    > üí° Futurs credentials pour vous connecter via l'interface web.  
  - L'URL d'acc√®s est indiqu√©e √† la fin du t√©l√©chargement : `http://10.7.0.10:8000`  

  - Pour faire d√©marrer automatiquement Splunk au boot :
    ```bash
    sudo /opt/splunk/bin/splunk enable boot-start
    ```
  - V√©rifier finalement que le service est up and running :
    ```bash
    sudo /opt/splunk/bin/splunk status
    ```  
    > **R√©sultat ‚úÖ‚ÄØ:** `splunkd` en cours d‚Äôex√©cution (PID‚ÄØxxxx) et tous les helpers actifs.  




### 4. Acc√®s au Splunk Dashboard
  - Sur la VM SOC‚ÄëWorkstation‚ÄØ:  
    - Ouvrir Firefox.  
    - Saisir `http://10.7.0.10:8000`.  
    - La page de connexion Splunk s‚Äôaffiche.  
    ![splunk-dash-1](./images/splunk-dash-1.png)  
    - Se connecter avec les identifiants cr√©√©s pr√©c√©demment.  
  > **R√©sultat ‚úÖ‚ÄØ:** Le tableau de bord Splunk Enterprise appara√Æt, confirmant que le serveur est fonctionnel et joignable depuis le r√©seau interne.  
    ![splunk-dash-2](./images/splunk-dash-2.png)  





### üìå Bilan
  - Splunk install√©, d√©marrage automatique configur√©, service actif sur le port‚ÄØ`8000`.  
  - Interface web accessible depuis la station analyste.    
  - Pr√™t pour la phase suivante‚ÄØ: configuration des inputs, forwarders et premi√®res recherches.    



> ‚ö†Ô∏è Snapshot‚ÄØ: prenez un snapshot de la VM SOC‚ÄëSplunk‚ÄëServer avant de poursuivre.





---




## Phase 4 - D√©ploiement du Universal Forwarder (SOC-W11)



### üéØ Objectif
Installer et configurer le **Splunk Universal Forwarder** sur la VM victime (SOC-W11), lui indiquer l‚Äôindexer (`10.7.0.10:9997`), d√©finir les sources d‚Äô√©v√©nements (Security, System, Application) et valider l‚Äôingestion des √©v√©nements dans l‚Äôindex `win_logs`.  



### 1. T√©l√©chargement du Forwarder
  - Ouvrir un navigateur depuis SOC-W11.    
  - Acc√©der √† la page de t√©l√©chargement du [Splunk Universal Forwarder](https://www.splunk.com/en_us/download/universal-forwarder.html?locale=en_us).    
  - T√©l√©charger le 64-bit Windows MSI localement.   
    ![uf-download-1](./images/uf-download-1.png)  




### 2. Installation du Forwarder
  - Lancer le `.msi` et suivre l‚Äôassistant :  
    - Chemin d‚Äôinstallation : C:\Program Files\SplunkUniversalForwarder  
    - Type : On-Premise (configur√© par d√©faut)  
    - Ex√©cuter en tant que Local System (option recommand√©e)   
  - D√©finir un compte d‚Äôadministration local pour le UF (ex : `splunk_agent` avec un mot de passe robuste).
  - Ignorer la configuration du Deployment Server (pas utilis√©e dans ce lab).  
  - Lors de la configuration de l‚Äô**Indexer**, d√©finir :  
    - Host/IP : `10.7.0.10`  
    - Port : `9997`     
    ![uf-download-2](./images/uf-download-2.png)    
    > ‚úÖ Cette √©tape g√©n√®re automatiquement un fichier `outputs.conf`.  




### 3. Activation du port de r√©ception sur l‚Äôindexer
M√™me si l‚ÄôIP de l‚Äôindexer (`10.7.0.10`) et le port de transmission (`9997`) ont √©t√© d√©finis lors de l‚Äôinstallation du UF, l'**indexer** doit explicitement √™tre configur√© pour √©couter sur ce port.     
  - Le Forwarder d√©finit uniquement la destination des journaux (`outputs.conf`).  
  - L‚ÄôIndexer doit, quant √† lui, √™tre configur√© pour accepter les flux entrants sur ce port, sans quoi les √©v√©nements seront ignor√©s.  

  - Depuis l‚Äôinterface Splunk (`http://10.7.0.10:8000`) :  
    1. Acc√©der √† **Settings ‚ûù Forwarding and Receiving**.  
    2. Dans **Receive data**, cliquer sur **Configure receiving**.  
    3. S√©lectionner **New Receiving Port** et ajouter le port `9997`.  
    4. Sauvegarder la configuration.    
    ![uf-port](./images/uf-port.png)   


  > üí° V√©rification c√¥t√© serveur :  
  > ```bash
  > sudo ss -tulnp | grep 9997
  > ```  
  > Le processus `splunkd` doit appara√Ætre en √©coute sur TCP/9997.  


**R√©sultat ‚úÖ :** L‚Äôindexer est d√©sormais configur√© pour recevoir les logs transmis par les UF sur le port 9997, garantissant la continuit√© du pipeline de collecte.





### 4. D√©finition des sources de logs via `inputs.conf`  
Apr√®s avoir reli√© le UF √† l‚Äôindexer (`outputs.conf`), d√©finir quels logs Windows seront collect√©s.  
  
Selon la [documentation officielle](https://docs.splunk.com/Documentation/Splunk/latest/Admin/Inputsconf), dans un environnement **sans Deployment Server** (comme dans ce lab), cela se fait par l'entremise du fichier de configuration `inputs.conf`, localis√© dans :  
  `C:\Program Files\SplunkUniversalForwarder\etc\system\local`   
  
  - `outputs.conf` ‚Üí indique **destination** (o√π envoyer) les donn√©es (`10.7.0.10:9997`).  
    ![uf-config-1](./images/uf-config-1.png)    
  - `inputs.conf` ‚Üí indique **sources** √† collecter (ex : logs Windows).    

  - Cr√©er manuellement `inputs.conf`, puis ajouter les **stanzas** suivants :   
    ```ini
    [WinEventLog://Security]
    disabled = 0
    index = win_logs
  
    [WinEventLog://System]
    disabled = 0
    index = win_logs

    [WinEventLog://Application]
    disabled = 0
    index = win_logs
    ```
    ![uf-config-2](./images/uf-config-2.png)  
      
    > üí° Ces stanzas activent la collecte des trois canaux de logs Windows les plus critiques (S√©curit√©, Syst√®me et Application) et les centralisent vers l'index `win_logs`.    


  - Apr√®s enregistrement, le UF contient d√©sormais :  
    - `outputs.conf` ‚Üí destination (`10.7.0.10:9997`)  
    - `inputs.conf` ‚Üí sources de logs √† collecter  
  ![uf-config-3](./images/uf-config-3.png)  

 
  - Appliquer/valider la configuration
    - Se positionner dans le r√©pertoire `C:\Program Files\SplunkUniversalForwarder\bin`  
    - Red√©marrer et v√©rifier l'√©tat du service :   
      ```powershell
      .\splunk restart
      .\splunk status
      ```  
    ![uf-config-4](./images/uf-config-4.png)


**R√©sultat ‚úÖ :** Le service SplunkForwarder red√©marre correctement.  
  - `splunk status` ‚Üí renvoie `SplunkForwarder: Running`, confirmant que le daemon `splunkd` tourne en arri√®re-plan et que les logs sont pr√™ts √† √™tre envoy√©s √† l‚Äôindexer (`10.7.0.10`).  



  

### 5. Cr√©ation de l'index `win_logs` 
  - Retour sur notre interface Splunk (`http://10.7.0.10:8000`)  
    - Aller dans Settings ‚ûù Indexes  
    - Cliquer sur New Index et configurer :  
      - Index Name : `win_logs`  
      - Laisser les autres param√®tres par d√©faut  
    - Valider en cliquant sur Save  
    ![uf-config-5](./images/uf-config-5.png)

    > ‚úÖ L‚Äôindex `win_logs` est d√©sormais pr√™t √† recevoir les √©v√©nements.  

  - V√©rification par **requ√™te SPL**
    - Dans l‚Äôapplication Search & Reporting, ex√©cuter :
      ```spl
      index="win_logs"
      ```  
      ![uf-config-6](./images/uf-config-6.png)  
        
      > ‚úÖ Apparition rapide d‚Äô√©v√©nements confirmant la bonne collecte des logs.
      



      
### üìå Bilan  
  - Universal Forwarder install√© et configur√© avec succ√®s sur SOC-W11  
  - Transmission confirm√©e vers l‚Äôindexer (port `9997` activ√©)  
  - Sources d√©finies (Security, System, Application)  
  - Index `win_logs` cr√©√© et aliment√© avec les premiers √©v√©nements  
    
    

> ‚ö†Ô∏è Snapshot‚ÄØ: prenez un snapshot des VMs SOC‚ÄëSplunk‚ÄëServer et SOC-W11 avant de poursuivre.  





---






## Phase 5 - Configuration du Honeypot

### üéØ Objectif  
  - D√©ployer un honeypot web sur IIS dans la VM SOC-W11 pour d√©tecter des activit√©s de reconnaissance.   
  - Cr√©er une page leurre (`/really-confidential-data.html`) ainsi qu‚Äôun faux fichier CSV (`totally-not-sensitive-2025.csv`) accompagn√©s d'un `fichier robots.txt` volontairement mal configur√© pour attirer et identifier les acc√®s suspects.  
  - Les acc√®s sont enregistr√©s dans les logs IIS, collect√©s par le Splunk Universal Forwarder puis centralis√©s dans l‚Äôindex `iis_logs` du SOC Splunk Server pour analyse/d√©tection en temps r√©el.  

> ‚ö†Ô∏è Le serveur IIS n‚Äôa pas √©t√© enrichi d‚Äôautres contenus, l‚Äôobjectif √©tant de se concentrer sur un seul endpoint vuln√©rable pour tester la d√©tection et les alertes.  




### 1. Installation IIS
  - Ouvrir **Control Panel ‚Üí Programs ‚Üí Turn Windows features on or off**.   
  - Activer **Internet Information Services** (cocher *Web Management Tools* et *World Wide Web Services*).    
    ![iis-1](./images/iis-1.png)  
  - V√©rifier le service en ouvrant `http://localhost` sur la VM : la page d‚Äôaccueil IIS doit s‚Äôafficher.    
    ![iis-2](./images/iis-2.png)    




### 2. Configuration de la journalisation IIS
  - Ouvrir `IIS Manager ‚Üí Sites ‚Üí Default Web Site ‚Üí Logging`  
  - S'assurer que les champs entr√©s respectent :  
    - Format : `W3C`  
    - R√©pertoire : `%SystemDrive%\inetpub\logs\LogFiles`  
    - Mode : Log file only  
    - Rollover : Daily  
    ![verif-2](./images/verif-2.png)  
    - Logging Fields : (voir capture)  
    ![verif-3](./images/verif-3.png)     
    ![verif-1](./images/verif-1.png)  




### 3. Cr√©er le contenu du Honeypot
  - Cr√©er page leurre HTML `really-confidential-data.html`  
    - Ouvrir le Notepad (ou tout √©diteur texte) avec les droits administrateur.  
    - Copier‚Äëcoller le code HTML fourni.  
    ```html
    <!doctype html>
    <html lang="en">
    <head>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <title>Customer Data Archive ‚Äî Confidential</title>
      <style>
        :root{--brand:#0b66c3;--muted:#777;--card:#fff;--bg:#f4f6f8}
        body{font-family: "Segoe UI", Roboto, Arial, sans-serif;background:var(--bg);color:#111;margin:28px}
        .container{max-width:1100px;margin:0 auto;background:var(--card);border:1px solid #e3e6ea;border-radius:8px;padding:22px;box-shadow:0 8px 30px rgba(15,30,45,0.04)}
        header{display:flex;align-items:center;gap:16px}
        .logo{width:84px;height:84px;background:linear-gradient(180deg,#0b66c3,#084f8f);color:#fff;display:flex;align-items:center;justify-content:center;border-radius:8px;font-weight:700;font-size:18px;box-shadow:0 4px 12px rgba(11,102,195,0.18)}
        .logo span{display:flex;align-items:center;gap:8px}
        .logo .flake{font-size:22px}
        h1{margin:0;font-size:20px;color:#0b3b66}
        .meta{color:var(--muted);margin:8px 0 18px;font-size:14px}
        .details{display:flex;flex-wrap:wrap;gap:12px;margin-bottom:18px}
        .details div{background:#fafbfc;padding:12px;border-radius:8px;border:1px solid #eef2f6;font-size:13px;min-width:160px}
        .download{margin:18px 0}
        .btn{display:inline-block;padding:10px 18px;background:var(--brand);color:#fff;border-radius:8px;text-decoration:none;font-weight:700;box-shadow:0 6px 18px rgba(11,102,195,0.16)}
        .btn:hover{background:#094a8f;transform:translateY(-1px);transition:all .12s ease}
        table{width:100%;border-collapse:collapse;margin-top:18px;background:#fff;border-radius:6px;overflow:hidden}
        th,td{padding:10px;border-bottom:1px solid #eef2f6;text-align:left;font-size:13px}
        th{background:#f7fafc;color:#333;font-weight:700}
        tbody tr:nth-child(even){background:#fbfdff}
        footer{margin-top:18px;font-size:12px;color:var(--muted)}
        .legal{margin-top:12px;color:#444;font-size:13px}
        .small-muted{font-size:12px;color:#999;margin-top:8px}
      </style>
    </head>
    <body>
      <div class="container" role="main" aria-labelledby="title">
        <header>
          <div class="logo" aria-hidden="true"><span class="flake">‚ùÑ</span><strong>SNOW</strong></div>
          <div>
            <h1 id="title">Customer Data Archive</h1>
            <div class="meta">Export generated for internal compliance review ‚Äî access restricted to authorized personnel only.</div>
          </div>
        </header>
    
        <section>
          <div class="details" aria-label="Export metadata">
            <div><strong>File name</strong><br>totally-not-sensitive-2025.csv</div>
            <div><strong>Status</strong><br>Confidential ‚Äî Do Not Distribute</div>
            <div><strong>Last updated</strong><br>2025-09-25 11:11 UTC</div>
            <div><strong>Owner</strong><br>Data Governance</div>
            <div><strong>Department</strong><br>Cybersecurity</div>
            <div><strong>Records</strong><br>12,483</div>
            <div><strong>Size</strong><br>93 GB</div>
          </div>
    
          <div class="download">
            <a class="btn" href="totally-not-sensitive-2025.csv" download aria-label="Download CSV Export">üì• Download CSV Export (93 GB)</a>
          </div>
    
          <div class="legal">
            <p><strong>Purpose:</strong> Export prepared by the Data Governance team for scheduled audit and validation tasks. Handle and retain under company retention policy.</p>
          </div>
    <table aria-label="sample preview">
      <thead>
        <tr>
          <th>id</th>
          <th>first_name</th>
          <th>last_name</th>
          <th>email</th>
          <th>country</th>
          <th>status</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>1</td><td>John</td><td>Doe</td><td>john.doe@snow.corp</td><td>üá∑üá∫</td><td>active</td></tr>
        <tr><td>2</td><td>Michael</td><td>Lalancette</td><td>michael.lalancette@snow.corp</td><td>üá®üá¶</td><td>active</td></tr>
        <tr><td>3</td><td>Edward</td><td>Snowden</td><td>edward.snowden@snow.corp</td><td>üá∫üá∏</td><td>inactive</td></tr>
        <tr><td>4</td><td>Linus</td><td>Torvalds</td><td>linus.torvalds@snow.corp</td><td>üá´üáÆ</td><td>inactive</td></tr>
      </tbody>
    </table>
    
    
          <footer>
            <p>Contact: data-governance@acme.corp ‚Äî For authorized use only.</p>
            <p class="small-muted">This document and the contained data are proprietary and confidential. Unauthorized access, use or distribution is strictly prohibited and may result in disciplinary or legal action.</p>
          </footer>
        </section>
      </div>
    </body>
    </html>
    ```

    - Enregistrer le fichier dans le r√©pertoire IIS sous  `C:\inetpub\wwwroot\really-confidential-data.html`  
    - V√©rifier l‚Äôacc√®s‚ÄØ: `http://localhost/really-confidential-data.html`  
       ![iis-3](./images/iis-3.png)  

    > üí° Cette page imite un document interne sensible et contient un lien de t√©l√©chargement destin√© √† pi√©ger les curieux.    





  - Cr√©er fichier CSV `totally-not-sensitive-2025.csv`
    - Ouvrir le Notepad (ou tout √©diteur texte) avec les droits administrateur.  
    - Copier-coller le contenu CSV :  
     ```csv
     ID;Col1;Col2;Col3;Col4;Col5
     0;"*** WARNING ***";"Nice try!";"You just fell into a honeypot.";"üíª";"Caught"
     1;"This incident has been logged.";"Your IP has been sent to Santa Claus.";"üéÖ";"Naughty List"
     ```  
    - Enregistrer le fichier dans le r√©pertoire IIS sous `C:\inetpub\wwwroot\totally-not-sensitive-2025.csv`   
    - Cliquer sur le lien de t√©l√©chargement pour v√©rifier le logging IIS.  
    ![iis-4](./images/iis-4.png)
 
    > üí° Ce fichier ne contient √©videmment aucune donn√©e r√©elle, uniquement un message d‚Äôavertissement destin√© aux curieux non autoris√©s.  






### 4. Cr√©er l'app√¢t `robots.txt`
  - Toujours dans `C:\inetpub\wwwroot`, cr√©er un fichier texte intitul√© `robots.txt`.  
  - Copier-coller le contenu texte :  
    ```txt
    User-agent: *
    Disallow: /really-confidential-data.html
    Disallow: /totally-not-sensitive-2025.csv
    ```
  > üí° Ce fichier ne constitue en aucun cas une mesure de s√©curit√©‚ÄØ; au contraire, il sert volontairement d‚Äôapp√¢t : il trahit la pr√©sence de ressources fictives aux outils de reconnaissance automatis√©s (gobuster, dirb, nikto, etc.).





### 5. Cr√©ation de l'index `iis_logs`
Avant d‚Äôenvoyer les journaux IIS vers Splunk, il faut cr√©er un index de destination. Sans cet index, les logs seraient ignor√©s.   
  - Sur l'interface Splunk, aller sur `Settings ‚Üí Indexes ‚Üí New Index`.   
    - Nommer l'index `iis_logs` et laisser les autres options par d√©faut.  
    - Sauvegarder.  
    ![iis-5](./images/iis-5.png)    
  > üí° L'index appara√Æt ensuite dans la liste avec le statut Active et recevra les logs IIS.   





### 6. Configurer le UF pour envoyer √©v√©nements vers `iis_logs`
Pour collecter les logs IIS d‚Äôune machine Windows, il faut √©diter manuellement le fichier `inputs.conf` du Forwarder afin de pr√©ciser :
- le chemin des logs IIS (C:\inetpub\logs\LogFiles\W3SVC1\*.log),  
- le sourcetype (iis),  
- l‚Äôindex de destination (iis_logs).

  - Modification de `inputs.conf` :
    - Sur la VM SOC-W11, √©diter `C:\Program Files\SplunkUniversalForwarder\etc\system\local\inputs.conf`, ajouter le bloc suivant :     
      ```ini
      [monitor://C:\inetpub\logs\LogFiles\W3SVC1\*.log]
      disabled = 0
      index = iis_logs
      sourcetype = iis
      crcLength = 1024
      crcSalt = <SOURCE>
      alwaysOpenFile = true
      ```
      ![iis-6](./images/iis-6.png)
 
    - Ce param√©trage permet au Forwarder de :  
      - surveiller de tous les fichiers `.log` du r√©pertoire IIS,  
      - envoyer les √©v√©nements vers l‚Äôindex `iis_logs`,  
      - utiliser le `sourcetype=iis` pour un parsing structur√© (txt brut ‚Üí champ structur√©),   
      - `crcSalt` et `alwaysOpenFile` assurent une lecture continue et √©vitent les doublons.  
     
  - Red√©marrer le service pour appliquer la nouvelle configuration.
    ```powershell
    cd 'C:\Program Files\SplunkUniversalForwarder\bin\'
    .\splunk restart
    ```

  - G√©n√©ration √©v√©nements et v√©rification des logs
    - Acc√©der au honeypot `http://localhost/really-confidential-data.html`.  
    - T√©l√©charger le CSV pour g√©n√©rer davantage de bruit.  
    - Valider qu'un log a bien √©t√© cr√©√© dans le r√©pertoire `C:\inetpub\logs\LogFiles\W3SVC1\`.  
      ![iis-7](./images/iis-7.png)

  - V√©rification dans Splunk
    - Depuis l'onglet `Search & Reporting`, lancer une recherche :
      ```spl
      index=iis_logs sourcetype=iis
      ```
      ![iis-8](./images/iis-8.png)

    > ‚úÖ Les √©v√©nements sont bien ing√©r√©s dans Splunk :  
    > - Source correcte (`C:\inetpub\logs\LogFiles\W3SVC1\`)  
    > - H√¥te identifi√© comme `SOC-W11`  
    > - Requ√™tes HTTP `GET` sur `/really-confidential-data.html` et `/totally-not-sensitive-2025.csv`  
      
  

**R√©sultat ‚úÖ :** Le honeypot web est op√©rationnel, les journaux IIS sont bien transmis et index√©s dans Splunk.
La prochaine √©tape consiste √† mettre en place une alerte temps r√©el pour d√©tecter automatiquement tout acc√®s au leurre.  







---






## Phase 6 - Configuration des Alertes

### üéØ Objectif  
D√©tecter, en temps r√©el, toute requ√™te HTTP vers le honeypot `/really-confidential-data.html` et :
  - journaliser dans Triggered Alerts (s√©v√©rit√©‚ÄØHigh) ;  
  - envoyer un e‚Äëmail (Mailtrap) ;  
  - √©crire dans `honeypot_hits.csv`.  




### **Cr√©er l'alerte :**  
  - Depuis `Search & Reporting`, ex√©cuter la requ√™te :
    ```spl
    index=iis_logs sourcetype=iis
    (cs_uri_stem="/really-confidential-data.html" OR uri_path="/really-confidential-data.html")
    | eval src_ip=coalesce(c_ip, client_ip, src)
    | eval user_agent=coalesce(cs_user_agent, cs_User_Agent, http_user_agent, User_Agent)
    | eval honeypot_uri=coalesce(cs_uri_stem, uri_path)
    | eval readable_time=strftime(_time, "%F %T")
    ```

  - Cliquer sur `Save As ‚Üí Alert`  
    - Title : ALERTE - Acc√®s Honeypot 
    - Description : D√©clench√©e lors d‚Äôun acc√®s √† la page `/really-confidential-data.html` (reconnaissance/√©num√©ration). 
    - Permissions : Private (puisqu'on est dans un lab isol√©).  
    - Alert Type : Real-time (pour d√©tection imm√©diate).  
    - Expires : 30 jours  

  > üí° Pour √©viter que des outils d‚Äô√©num√©ration tels que `Gobuster`, `Dirb`, etc. ne g√©n√®rent une avalanche d‚Äôalertes, j‚Äôai configur√© l‚Äôalerte afin qu‚Äôelle ne se d√©clenche qu‚Äôune fois par rafale, en utilisant une fen√™tre de 1‚ÄØminute et un throttling de 5‚ÄØminutes. Ainsi, les acc√®s r√©p√©t√©s dans ce laps de temps sont ignor√©s, limitant le bruit tout en conservant la visibilit√© sur chaque incident.  

  - Trigger Condition : Number of Results > 0   
  - Time Window : 1 minute 
  - Trigger Alert : Once  
  - Suppress triggering for : 5 minutes (throttle)  
  ![alerte-1](./images/alerte-1.png)

  > ‚úÖ En r√©sum√©, l‚Äôalerte se d√©clenche d√®s la premi√®re visite du Honeypot, puis, gr√¢ce √† un throttle de‚ÄØ5‚ÄØminutes, les acc√®s r√©p√©t√©s sont ignor√©s. L‚Äô√©v√©nement reste consign√© et consultable, mais 1 seul e‚Äëmail et 1 seule alerte sont envoy√©s pour chaque fen√™tre d‚Äôincident.





### **Trigger Actions :**  

D√©finir ce qui arrive lorsqu'une alerte se d√©clenche.    



#### Action 1 ‚Äì Add to Triggered Alerts  
- **Severity :** High  
  ![alerte-2](./images/alerte-2.png)  
> üí° Toute visite de la page honeypot est par d√©finition suspecte ‚Üí s√©v√©rit√© haute.  



#### Action 2 ‚Äì Send Email

1. **Cr√©er un compte Mailtrap**
   - S'inscrire sur [Mailtrap.io](https://mailtrap.io).  
   - L‚Äôoffre gratuite fournit un serveur SMTP et une bo√Æte *sandbox* suffisante pour les tests du SOC-LAB.  
  > üí° **Email Sandbox** de Mailtrap est sp√©cifiquement con√ßue pour tester l‚Äôenvoi d‚Äôe-mails en environnement de test/d√©veloppement, sans sortie vers l‚Äôext√©rieur.   


2. **R√©cup√©rer les identifiants SMTP**
   - Dans le tableau de bord Mailtrap : Sandbox ‚Üí SMTP credentials    
     ![alerte-3](./images/alerte-3.png)   


3. **Configurer SMTP dans Splunk**  
  - Dans Splunk : Settings ‚Üí Server Settings ‚Üí Email Settings   
  - D√©finir le serveur utilis√© par Splunk pour acheminer les alertes :  
    - Mail host : `sandbox.smtp.mailtrap.io`  
    - Email security : Enable TLS  
    - Username : `62d2abc10f2b15`  
    - Password : `*********`  
    - Allowed domains : `soc-admin.local`   
     ![alerte-4](./images/alerte-4.png)  

   - Link hostname : `secops-desktop` (√† d√©finir dans `/etc/hosts`)    
     ![alerte-5](./images/alerte-5.png)    
     > üí° Garantit que lorsqu‚Äôun e-mail d‚Äôalerte contient une URL du type `http://secops-desktop:8000/en-US/app/search/...` le poste analyste r√©sout `secops-desktop` vers l‚ÄôIP du serveur Splunk m√™me sans DNS interne.     

   - Send email as : `alerts@siem.soclab.local`  
     ![alerte-6](./images/alerte-6.png)   


4. **Notification par e-mail**

  Alerte imm√©diatement le SOC √† chaque acc√®s √† la page honeypot.  
  - To : soc-alerts@soc-admin.local  
  - Priority : High  
  - Subject : ALERTE - Acc√®s Honeypot  
  - Message :  
    ```bash
    La page honeypot /really-confidential-data.html a √©t√© consult√©e.
    
    Host : $result.host$
    IP src : $result.src_ip$
    Time : $result.readable_time$
    User-Agent : $result.user_agent$
    ```   
    ![alerte-7](./images/alerte-7.png)   




    
#### Action 3 ‚Äì Output results to lookup
Consigner chaque hit sur la page honeypot dans un fichier CSV pour historique/corr√©lation.  
  - **File name :** `honeypot_hits.csv`  
  - **Mode :** `Append` (ajout non destructif)   
    ![alerte-8](./images/alerte-8.png)   


> ‚úÖ Apr√®s avoir activ√© les trois actions ‚Äî Triggered Alerts, Send Email, et Output to Lookup ‚Äî sauvegarder l‚Äôalerte.  






### V√©rification end-to-end  
  Confirmer que l‚Äôalerte temps r√©el d√©clenche les 3 actions (Triggered Alerts, e-mail, lookup CSV) lors d‚Äôun acc√®s √† `/really-confidential-data.html`.   

  
  1) **G√©n√©ration de l‚Äô√©v√©nement**  
    - Depuis **SOC-Workstation**, ouvrir :    
      `http://10.7.0.20/really-confidential-data.html`    
      ![alerte-9](./images/alerte-9.png)    

  
  2) **R√©ception du e-mail d'alerte**  
    - V√©rifier que **tous les champs** sont renseign√©s (Host, IP src, Time, User-Agent).  
      ![alerte-10](./images/alerte-10.png)   

      > ‚úÖ Lien direct vers le log sp√©cifique dans Splunk.   
      ![alerte-11](./images/alerte-11.png)       
  
  
  4) **V√©rifier Triggered Alerts**
    - **Activity ‚Üí Triggered Alerts** : une entr√©e **Severity = High** au moment du test.  
    - Le lien **View results** renvoie vers la recherche qui a d√©clench√©.  
      ![alerte-12](./images/alerte-12.png)       
  
  
  5) **V√©rifier le lookup CSV**  
      ```spl  
      | inputlookup honeypot_hits.csv
      ```
      ![alerte-13](./images/alerte-13.png)         



  > üìå Bilan : pipeline valid√© ‚Äî d√©tection temps r√©el, e-mail, CSV lookup.  





---





## Phase 7 ‚Äî Reconnaissance simul√©e

### üéØ Objectif
Simuler une phase de reconnaissance/√©num√©ration c√¥t√© attaquant et v√©rifier que l‚Äôacc√®s au leurre `/really-confidential-data.html` d√©clenche l‚Äôalerte et alimente les logs.   

> üí° D√©monstration volontairement simplifi√©e : l‚Äôobjectif est de valider le pipeline de d√©tection/alerte, pas de conduire une campagne offensive compl√®te.  
---



#### 1) Scan de ports (Nmap)
  - Depuis la VM Kali (SOC-ATK), lancer un TCP SYN scan furtif (`-sS`) avec d√©tection de version (`-sV`) et scripts par d√©faut (`-sC`) √† la machine victime (SOC-W11) :  
    ```bash
    nmap -sS -sV -sC -Pn -T3 10.7.0.20
    ```  
    > ‚úÖ Cette commande :  
      >- `sS` : scan TCP SYN furtif (√©vite le 3-way handshake complet, plus discret).    
      >- `sV` : d√©tection de versions (identifie le logiciel/service derri√®re chaque port ouvert).  
      >- `sC` : ex√©cute les scripts nmap par d√©faut ce qui comprend titre HTTP, infos SSL, m√©tadonn√©es de service (c'est gr√¢ce √† ce scan que l'attaquant va voir les leurres).    
      >- `Pn` : ignore la d√©couverte d‚Äôh√¥te = pas d‚ÄôICMP (suppose la cible "up", utile si le ping est bloqu√©).    
      >- `T3` : profil temporel ‚ÄúNormal‚Äù (bon middle ground entre vitesse et discr√©tion).       


  - Les r√©sultats sont revenus rapidement : le port 80 est ouvert et sert du contenu via Microsoft IIS 10.0.  
    - Indices pertinents observ√©s :  
      - Pr√©sence de `/robots.txt` avec 2 entr√©es **Disallowed** (ressources cach√©es).  
      - Leurres expos√©s : `/really-confidential-data.html` et `totally-not-sensitive-2025.csv`.  
      - M√©thode HTTP TRACE accept√©e (mauvaise pratique).  
      - H√¥te Microsoft Windows confirm√© (r√©solution MAC/ARP).   
        ![atk-1](./images/atk-1.png)   





#### 2) Exploration
Apr√®s avoir rep√©r√© `/really-confidential-data.html`, privil√©gier une collecte discr√®te en CLI pour r√©duire les artefacts forensiques : utiliser `curl/wget` plut√¥t qu‚Äôun navigateur.  
  - Consulter la page `/really-confidential-data.html` avec `curl` :   
      ```bash
      curl http://10.7.0.20/really-confidential-data.html
      ```
      ![atk-2](./images/atk-2.png)  
      ![atk-2.5](./images/atk-2.5.png)  
      > üí° La page simule des donn√©es sensibles et expose un lien de t√©l√©chargement.  

  - T√©l√©charger le CSV associ√© avec `wget` :   
      ```bash 
      wget http://10.7.0.20/totally-not-sensitive-2025.csv
      ```    
      ![atk-3](./images/atk-3.png)  
      ![atk-4](./images/atk-4.png)
      > üí° Le CSV est un leurre contr√¥l√© (message d‚Äôavertissement, aucune donn√©e r√©elle).       






---






## Phase 8 ‚Äî Flow SOC

### üéØ Objectif
Valider le flux op√©rationnel complet du lab :  
  `acc√®s au leurre ‚Üí alerte temps r√©el ‚Üí triage analyste ‚Üí visualisation dans Splunk`  

  1) üö® **D√©clenchement**
  - D√©clencheur : acc√®s √† `/really-confidential-data.html` depuis VM attaquante (SOC-ATK).  
  - Flow : `alerte splunk ‚Üí SMTP Mailtrap ‚Üí soc-alerts@soc-admin.local`  
    - M√©tadonn√©es observ√©es dans l'e-mail :  
        - Host : `SOC-W11`  
        - IP src : `10.7.0.30`  
        - Time : `2025-09-28 12:59:02`  
        - User-Agent : `curl/8.15.0`  
        ![mailtrap-1](./images/mailtrap-1.png)     
        > üí° Lecture rapide : sujet explicite, champs cl√©s pr√©sents, lien direct `View results` vers Splunk.



  

  2) üë®‚Äçüíª **Triage analyste dans Splunk (N1)**
  - Depuis le lien de l‚Äôalerte, `View Results` et  `New Search` s‚Äôouvre sur l‚Äô√©v√©nement d√©clencheur (logs IIS).  
      ![mailtrap-2](./images/mailtrap-2.png)  
      ![mailtrap-3](./images/mailtrap-3.png)  
    - En aggrandissant les indexed fields, on obtient plusieurs donn√©es pertinentes :  
      ![mailtrap-4](./images/mailtrap-4.png)  





  
  3) üë®‚Äçüíª **V√©rification t√©l√©chargement du CSV (progression de l'intrusion)**  
  - En modifiant la requ√™te SPL, on peut voir que l'attaquant a √©galement t√©l√©charg√© le CSV :  
      ![mailtrap-5](./images/mailtrap-5.png)   
    > üí° Signal SOC : s√©quence `curl` ‚Üí `wget` = progression de kill chain du rep√©rage/recon vers la collecte/exfiltration.  






  4) üìä **Dashboard pour monitorer le Honeypot**
Centraliser la visibilit√© sur les acc√®s au leurre, acc√©l√©rer le triage (qui/quoi/quand/comment) et fournir un point d‚Äôentr√©e analyste.  
  
  - Cr√©ation : `Search & Reporting ‚Üí Onglet Dashboards ‚Üí Create new dashboard`  
    - Nom : Dashboard - Acc√®s Honeypot  
    - Description : Monitoring en temps r√©el des acc√®s au honeypot IIS  
    - Permissions : Private  
    - Type : Classic Dashboards   
    ![dash-1](./images/dash-1.png)   

    > üí° Mon dashboard n'est qu'un exemple parmi tant d'autre, √† vous de vous amusez avec les diff√©rentes features que Splunk propose.





  - Ajout du premier panel : `Add Panel ‚Üí New ‚Üí Statistics Table`  
    -  Title : √âv√©nements r√©cents - Acc√®s Honeypot (IIS)  
    -  Time range : derniers 24h  
    -  Search (SPL) :  
      ```spl
    index="iis_logs" sourcetype="iis"
    (cs_uri_stem="/really-confidential-data.html" OR cs_uri_stem="/totally-not-sensitive-2025.csv" OR cs_uri_stem="/robots.txt")
    | eval honeypot_uri=coalesce(cs_uri_stem, uri_path)
    | eval user_agent=coalesce(cs_user_agent, cs_User_Agent, http_user_agent, User_Agent)
    | eval src_ip=coalesce(c_ip, client_ip, src)
    | eval method=coalesce(cs_method, method)
    | fields _time host honeypot_uri src_ip user_agent method sc_status

      ```
    ![dash-2](./images/dash-2.png)      

    > üí° Toujours valider le search string avant d'ajouter au dashboard.  
    ![dash-3](./images/dash-3.png)  
    




  - Ajout du deuxi√®me panel : `Add Panel ‚Üí New ‚Üí Statistics Table`   
    -  Title : Sources les plus actives - hits & fen√™tre d'attaque  
    -  Time range : derniers 24h  
    -  Search (SPL) :  
      ```spl
      index=iis_logs sourcetype=iis cs_uri_stem="/really-confidential-data.html"
      | eval src_ip=coalesce(c_ip, client_ip, src), user_agent=coalesce(cs_User_Agent, cs_user_agent, http_user_agent, User_Agent)
      | stats count AS hits values(sc_status) AS http_codes min(_time) AS first_seen max(_time) AS last_seen BY src_ip user_agent
      | eval first_seen=strftime(first_seen, "%F %T"), last_seen=strftime(last_seen, "%F %T")
      | sort - hits
      ```
      ![dash-4](./images/dash-4.png)      

    > üí° Valider avec le search string avant d'ajouter au dashboard.   





  - Ajout d'un panel simple (single value) : `Add Panel ‚Üí New ‚Üí Single value`  
    -  Title : Nombre d'acc√®s (derniers 24h) 
    -  Time range : derniers 24h  
    -  Search (SPL) : 
    ```spl
     index="iis_logs" sourcetype="iis" 
    (cs_uri_stem="/really-confidential-data.html" 
     OR cs_uri_stem="/totally-not-sensitive-2025.csv" 
     OR cs_uri_stem="/robots.txt")
    | stats count AS total_access
    ```  
    ![dash-5](./images/dash-5.png)   

    > üí° UI : J'ai mis un gradient de couleurs passant de vert √† rouge tout d√©pendant du nombre d'acc√®s.  
    ![dash-6](./images/dash-6.png)  






  - Ajout d'un panel graphique (pie chart) : `Add Panel ‚Üí New ‚Üí Pie Chart`  
    -  Title : R√©partition par IP source (Top 10)  
    -  Time range : derniers 24h  
    -  Search (SPL) : 
    ```spl
    index=iis_logs sourcetype=iis (cs_uri_stem="/really-confidential-data.html" OR uri_path="/really-confidential-data.html")
    | eval src_ip=coalesce(c_ip, client_ip, src)
    | stats count AS hits by src_ip
    | sort - hits
    | head 10
    ```  
    ![dash-7](./images/dash-7.png)   



    > ‚úÖ Ajouter le dashboard √† la page d'accueuil ‚Üí `Set as home dashboard`  
    > Il appara√Ætra √† chaque ouverture de session :  
    ![dash-8](./images/dash-8.png)    





---

## Phase 9 - Rapport d'incident SOC

#### R√©sum√© ex√©cutif
  Le lab SOC a d√©tect√© et analys√© une tentative d‚Äôacc√®s non autoris√©e au leurre `/really-confidential-data.html`. L‚Äô√©v√©nement principal provient d‚Äôune VM Kali (`10.7.0.30`) utilisant `curl`, suivi d‚Äôun t√©l√©chargement confirm√© du leurre `/totally-not-sensitive-2025.csv` via `Wget`, indiquant une progression du rep√©rage vers la collecte/exfiltration.  
  > ‚úÖ Le pipeline de d√©tection (`SPL ‚Üí alerte ‚Üí SMTP`) et le dashboard Splunk ont fonctionn√© comme pr√©vu.  




#### Scope d'investigation  
- Index analys√© : `iis_logs`  
- Sourcetype : `iis`  
- Fichier logs : `C:\inetpub\logs\LogFiles\W3SVC1\...`
- 






























